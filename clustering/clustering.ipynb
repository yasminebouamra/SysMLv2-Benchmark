{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Get the absolute path of the parent directory\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "\n",
    "# Add the parent directory to sys.path\n",
    "sys.path.append(parent_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities import read_files\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from openai import OpenAI\n",
    "from umap import UMAP\n",
    "import csv\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.cluster import HDBSCAN\n",
    "from sklearn.cluster import ward_tree\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.metrics import davies_bouldin_score\n",
    "from sklearn.metrics import calinski_harabasz_score\n",
    "from sklearn.decomposition import PCA\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embeddings(tokenizer, model, code_snippet):\n",
    "    inputs = tokenizer(code_snippet, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    token_embeddings = outputs.last_hidden_state\n",
    "    \n",
    "    code_embedding = torch.mean(token_embeddings, dim=1)\n",
    "    \n",
    "    return code_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_files_openai(df, embedding_model = \"text-embedding-3-large\"):\n",
    "    return df['text'].apply(lambda x : OpenAI().embeddings.create(input=x, model= embedding_model).data[0].embedding)\n",
    "\n",
    "def embed_files_graphcodebert(df):\n",
    "    tokenizer_graphCodeBert = AutoTokenizer.from_pretrained(\"microsoft/graphcodebert-base\")\n",
    "    model_graphCodeBert = AutoModel.from_pretrained(\"microsoft/graphcodebert-base\")\n",
    "    return df['text'].apply(lambda x : generate_embeddings(tokenizer_graphCodeBert, model_graphCodeBert, x)[0])\n",
    "\n",
    "\n",
    "def prepare_and_process(in_path, out_path, embdding_function = embed_files_openai):\n",
    "    files = read_files(in_path)\n",
    "    df = pd.DataFrame([[file, open(file, \"r\").read(), len(open(file, \"r\").read().split(\" \"))] for file in files], columns=[\"file\", \"text\", \"token_count\"])    \n",
    "    df = df[df[\"token_count\"] < 8000] \n",
    "    df[\"embedding\"] = embdding_function(df)\n",
    "    df.to_pickle(out_path)\n",
    "    return df\n",
    "\n",
    "def load_df(path):\n",
    "    return pd.read_pickle(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at microsoft/graphcodebert-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "df_oa = prepare_and_process(\"../data/examples\", \"./pickles/df_text_embedding_large.pkl\", embed_files_openai)\n",
    "df_gb = prepare_and_process(\"../data/examples\", \"./pickles/df_graphcodebert.pkl\", embed_files_graphcodebert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_clusterings(df):\n",
    "    # HDBSCAN\n",
    "    clusterer = HDBSCAN(min_cluster_size=5, metric='cosine')\n",
    "    clusterer.fit(df[\"embedding\"].to_list())\n",
    "    df[\"hdbscan_labels\"] = clusterer.labels_\n",
    "\n",
    "    # KMeans\n",
    "    kmeans = KMeans(n_clusters=10, random_state=0).fit(df[\"embedding\"].to_list())\n",
    "    df[\"kmeans_labels\"] = kmeans.labels_\n",
    "\n",
    "    # Agglomerative Clustering\n",
    "    agg = AgglomerativeClustering(n_clusters=10).fit(df[\"embedding\"].to_list())\n",
    "    df[\"agg_labels\"] = agg.labels_\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_oa = run_clusterings(df_oa)\n",
    "df_gb = run_clusterings(df_gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_clusters(df):\n",
    "    slilhouette_score_hdbscan = silhouette_score(df[\"embedding\"].to_list(), df[\"hdbscan_labels\"])\n",
    "    slilhouette_score_kmeans = silhouette_score(df[\"embedding\"].to_list(), df[\"kmeans_labels\"])\n",
    "    slilhouette_score_agg = silhouette_score(df[\"embedding\"].to_list(), df[\"agg_labels\"])\n",
    "    \n",
    "    davies_bouldin_score_hdbscan = davies_bouldin_score(df[\"embedding\"].to_list(), df[\"hdbscan_labels\"])\n",
    "    davies_bouldin_score_kmeans = davies_bouldin_score(df[\"embedding\"].to_list(), df[\"kmeans_labels\"])\n",
    "    davies_bouldin_score_agg = davies_bouldin_score(df[\"embedding\"].to_list(), df[\"agg_labels\"])\n",
    "    \n",
    "    calinski_harabasz_score_hdbscan = calinski_harabasz_score(df[\"embedding\"].to_list(), df[\"hdbscan_labels\"])\n",
    "    calinski_harabasz_score_kmeans = calinski_harabasz_score(df[\"embedding\"].to_list(), df[\"kmeans_labels\"])\n",
    "    calinski_harabasz_score_agg = calinski_harabasz_score(df[\"embedding\"].to_list(), df[\"agg_labels\"])\n",
    "    \n",
    "    return {\"hdbscan\": [slilhouette_score_hdbscan, davies_bouldin_score_hdbscan, calinski_harabasz_score_hdbscan],\n",
    "            \"kmeans\": [slilhouette_score_kmeans, davies_bouldin_score_kmeans, calinski_harabasz_score_kmeans],\n",
    "            \"agg\": [slilhouette_score_agg, davies_bouldin_score_agg, calinski_harabasz_score_agg]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_with_UMAP(df):\n",
    "    \n",
    "    umap = UMAP(n_components=2, random_state=0)\n",
    "    umap_results = umap.fit_transform(df[\"embedding\"].to_list())\n",
    "    \n",
    "    # component one is x, component two is y\n",
    "    df[\"viz_x\"] = umap_results[:,0]\n",
    "    df[\"viz_y\"] = umap_results[:,1]\n",
    "    \n",
    "    return df\n",
    "\n",
    "def visualize_with_pca(df):\n",
    "    \n",
    "    pca = PCA(n_components=2)\n",
    "    pca_results = pca.fit_transform(df[\"embedding\"].to_list())\n",
    "    \n",
    "    # component one is x, component two is y\n",
    "    df[\"viz_x\"] = pca_results[:,0]\n",
    "    df[\"viz_y\"] = pca_results[:,1]\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_explanations_to_html(out_path):\n",
    "    explanations = \"\"\"\n",
    "    <div style=\"margin-top: 20px; font-family: Arial, sans-serif;\">\n",
    "        <h3>Score Descriptions:</h3>\n",
    "        <ul>\n",
    "            <li><b>Silhouette Score:</b> Measures how similar a point is to its own cluster compared to other clusters. Higher values indicate better-defined clusters.</li>\n",
    "            <li><b>Davies-Bouldin Score:</b> A measure of cluster separation and compactness. Lower values are better.</li>\n",
    "            <li><b>Calinski-Harabasz Score:</b> Measures the ratio of within-cluster dispersion to between-cluster dispersion. Higher values indicate better clustering.</li>\n",
    "        </ul>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    \n",
    "    with open(out_path, \"a\") as html_file:\n",
    "        html_file.write(explanations)\n",
    "\n",
    "def plot_clusters(df, out_path, visualization_function):\n",
    "    \n",
    "    df = visualization_function(df)\n",
    "    \n",
    "    # Define specs for mixed types: 'xy' for scatter plots and 'domain' for tables\n",
    "    specs = [\n",
    "        [{\"type\": \"xy\"}, {\"type\": \"xy\"}],  # Scatter plots in the first row\n",
    "        [{\"type\": \"domain\"}, {\"type\": \"domain\"}]  # Tables in the second row\n",
    "    ]\n",
    "    \n",
    "    # Create subplots\n",
    "    fig = make_subplots(\n",
    "        rows=2, cols=2,\n",
    "        specs=specs,\n",
    "        subplot_titles=(\"HDBSCAN\", \"KMeans\", \"Agglomerative Clustering\")\n",
    "    )\n",
    "    \n",
    "    # Add scatter plots with hover text showing the cluster label\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=df[\"viz_x\"], \n",
    "            y=df[\"viz_y\"], \n",
    "            mode='markers',\n",
    "            marker=dict(color=df[\"kmeans_labels\"], showscale=True),\n",
    "            text=[f\"Cluster: {line[1][\"kmeans_labels\"]}, File :{line[1][\"file\"]}\" for line in df.iterrows()],\n",
    "            hoverinfo=\"text\",\n",
    "            name=\"KMeans\"\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=df[\"viz_x\"], \n",
    "            y=df[\"viz_y\"], \n",
    "            mode='markers',\n",
    "            marker=dict(color=df[\"agg_labels\"], showscale=True),\n",
    "            text=[f\"Cluster : {line[1][\"agg_labels\"]}, File :{line[1][\"file\"]}\" for line in df.iterrows()],\n",
    "            hoverinfo=\"text\",\n",
    "            name=\"Agglomerative\"\n",
    "        ),\n",
    "        row=1, col=2\n",
    "    )\n",
    "    \n",
    "    fig.update_layout(\n",
    "        plot_bgcolor=\"#f4f4f4\",\n",
    "        paper_bgcolor=\"#f4f4f4\"\n",
    "    )\n",
    "    \n",
    "    # Evaluate clusters\n",
    "    cluster_eval = evaluate_clusters(df)\n",
    "    \n",
    "    formatted_kmeans = [f\"{score:.4f}\" for score in cluster_eval[\"kmeans\"]]\n",
    "    formatted_agg = [f\"{score:.4f}\" for score in cluster_eval[\"agg\"]]\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Table(header=dict(values=[\"Score\", \"Value\"]),\n",
    "                 cells=dict(values=[\n",
    "                     [\"Silhouette Score\", \"Davies Bouldin Score\", \"Calinski Harabasz Score\"],\n",
    "                     formatted_kmeans\n",
    "                 ])),\n",
    "        row=2, col=1\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Table(header=dict(values=[\"Score\", \"Value\"]),\n",
    "                 cells=dict(values=[\n",
    "                     [\"Silhouette Score\", \"Davies Bouldin Score\", \"Calinski Harabasz Score\"],\n",
    "                     formatted_agg\n",
    "                 ])),\n",
    "        row=2, col=2\n",
    "    )\n",
    "    \n",
    "    # Save to HTML\n",
    "    fig.write_html(out_path)\n",
    "    \n",
    "    # Append explanations\n",
    "    append_explanations_to_html(out_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\z004x5km\\.conda\\envs\\prompting_playground\\Lib\\site-packages\\umap\\umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n",
      "c:\\Users\\z004x5km\\.conda\\envs\\prompting_playground\\Lib\\site-packages\\umap\\umap_.py:1952: UserWarning:\n",
      "\n",
      "n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "plot_clusters(df_oa, \"./html_figures/clusterings_openai_UMAP.html\", visualize_with_UMAP)\n",
    "plot_clusters(df_oa, \"./html_figures/clusterings_openai_PCA.html\", visualize_with_pca)\n",
    "\n",
    "plot_clusters(df_gb, \"./html_figures/clusterings_graphcodebert_UMAP.html\", visualize_with_UMAP)\n",
    "plot_clusters(df_gb, \"./html_figures/clusterings_graphcodebert_PCA.html\", visualize_with_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gb.to_pickle(\"./pickles/df_graphcodebert.pkl\")\n",
    "df_oa.to_pickle(\"./pickles/df_text_embedding_large.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a pie chart of files per cluster\n",
    "\n",
    "fig = px.pie(df_gb, names='hdbscan_labels', title='HDBSCAN Clusters')\n",
    "fig.update_layout(\n",
    "    title='HDBSCAN Clusters',\n",
    "    plot_bgcolor=\"#f4f4f4\",\n",
    "    paper_bgcolor=\"#f4f4f4\"\n",
    ")\n",
    "fig.write_html(\"./html_figures/hdbscan_clusters.html\")\n",
    "\n",
    "fig = px.pie(df_gb, names='kmeans_labels', title='KMeans Clusters')\n",
    "fig.update_layout(\n",
    "    title='KMeans Clusters',\n",
    "    plot_bgcolor=\"#f4f4f4\",\n",
    "    paper_bgcolor=\"#f4f4f4\"\n",
    ")\n",
    "fig.write_html(\"./html_figures/kmeans_clusters.html\")\n",
    "\n",
    "fig = px.pie(df_gb, names='agg_labels', title='Agglomerative Clusters')\n",
    "fig.update_layout(\n",
    "    title='Agglomerative Clusters',\n",
    "    plot_bgcolor=\"#f4f4f4\",\n",
    "    paper_bgcolor=\"#f4f4f4\"\n",
    ")\n",
    "fig.write_html(\"./html_figures/agg_clusters.html\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prompting_playground",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
